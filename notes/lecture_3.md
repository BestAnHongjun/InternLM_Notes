# 【Lecture 3】基于InternLM和LangChain搭建你的知识库

未完成，更新学习中...

## 一、大模型开发范式

### 1.LLM的局限性
* 知识时效性受限：如何让LLM能够获取最新的知识
* 专业能力有限：如何打造垂域大模型
* 定制化成本高：如何打造个人专属的LLM应用

### 2.两种开发范式-RAG v.s. Finetune

#### (1)RAG

给大模型外挂一个知识库，根据用户提问，首先到知识库匹配相关文档，然后将提问和文档一起交给大模型生成回答。

![](../attach/lecture_3_1.JPG)

#### (2)Finetune

在一个轻量级的较小数据集上进行微调，从而提升模型在该新数据集上的能力。

#### (3)范式对比

两种范式**都可突破LLM的通用局限**，但各自特点如下：

|RAG|Finetune|
|:-:|:-:|
|低成本|成本高昂|
|可实时更新|无法实时更新|
|受基座模型影响大|可个性化微调|
|单次回答知识有限|知识覆盖面广|

## 二、LangChain简介
## 三、构建向量知识库
## 四、搭建知识库助手
## 五、Web Demo部署
## 六、动手实战环节